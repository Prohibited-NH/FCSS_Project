{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "90afc266-13df-4614-84e5-c51bca3bfc0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\r\n",
    "# Author 1:             Naseer Haider\r\n",
    "# Author 2:             Wahid Ahmed\r\n",
    "# Author 3:             Muhammad Danish Kizahakke \n",
    "# Author 4:              Muhammad Usama Rahim_\n",
    "# File:                 FCSS_Project.ipynb\r\n",
    "##################################################################################\r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1f69a5-ccf7-44ec-9ae9-e2fc27e3ff82",
   "metadata": {},
   "source": [
    "<h1>Part 1: Downloading the Required Datasets</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bb988c-9a55-4fc0-bc1d-697296dc8c6d",
   "metadata": {},
   "source": [
    "#### - This part involves importing necessary packages and downloading the required datasets.\n",
    "#### - We use `kagglehub` to download the Book-Crossing dataset from Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "e73143e9-548f-4520-9fb3-0d2d255346fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Book-Crossing dataset...\n",
      "Path to Book-Crossing dataset files: C:\\Users\\User\\.cache\\kagglehub\\datasets\\somnambwl\\bookcrossing-dataset\\versions\\1\n",
      "Datasets downloaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Importing packages\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "\n",
    "# Function to download datasets\n",
    "def download_datasets():\n",
    "    print(\"Downloading Book-Crossing dataset...\")\n",
    "    # Downloading Book-Crossing dataset from Kaggle\n",
    "    book_crossing_path = kagglehub.dataset_download(\"somnambwl/bookcrossing-dataset\")\n",
    "    print(\"Path to Book-Crossing dataset files:\", book_crossing_path)\n",
    "\n",
    "    print(\"Datasets downloaded successfully.\")\n",
    "\n",
    "# Download the datasets\n",
    "download_datasets()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47076ea-60d0-4350-bdf0-3a61ee3d21fe",
   "metadata": {},
   "source": [
    "# Part 2: Filtering the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106d1fba-84b3-48a5-9b63-a9e302b975fd",
   "metadata": {},
   "source": [
    "#### - This part filters the Book-Crossing dataset to keep only books rated by at least 50 users.\n",
    "#### - It also filters users who have rated at least 50 books.\n",
    "#### - The goal is to have a more focused dataset with sufficient data for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a98af1dd-decc-45ac-9268-75872b157310",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Book-Crossing datasets...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_26376\\4227661504.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  users = pd.read_csv(users_file_path, sep=';', encoding='latin-1', on_bad_lines='skip')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         ISBN                                              Title  \\\n",
      "0  0195153448                                Classical Mythology   \n",
      "1  0002005018                                       Clara Callan   \n",
      "2  0060973129                               Decision in Normandy   \n",
      "3  0374157065  Flu: The Story of the Great Influenza Pandemic...   \n",
      "4  0393045218                             The Mummies of Urumchi   \n",
      "\n",
      "                 Author  Year                Publisher  \n",
      "0    Mark P. O. Morford  2002  Oxford University Press  \n",
      "1  Richard Bruce Wright  2001    HarperFlamingo Canada  \n",
      "2          Carlo D'Este  1991          HarperPerennial  \n",
      "3      Gina Bari Kolata  1999     Farrar Straus Giroux  \n",
      "4       E. J. W. Barber  1999   W. W. Norton & Company  \n",
      "Index(['ISBN', 'Title', 'Author', 'Year', 'Publisher'], dtype='object')\n",
      "   User-ID        ISBN  Rating\n",
      "0   276725  034545104X       0\n",
      "1   276726  0155061224       5\n",
      "2   276727  0446520802       0\n",
      "3   276729  052165615X       3\n",
      "4   276729  0521795028       6\n",
      "Index(['User-ID', 'ISBN', 'Rating'], dtype='object')\n",
      "  User-ID  Age\n",
      "0       1  NaN\n",
      "1       2   18\n",
      "2       3  NaN\n",
      "3       4   17\n",
      "4       5  NaN\n",
      "Index(['User-ID', 'Age'], dtype='object')\n",
      "Merging Ratings and Books datasets...\n",
      "Filtering books with at least 50 ratings...\n",
      "Filtering users who have rated at least 50 books...\n",
      "Filtered Book-Crossing dataset saved to filtered_book_crossing.csv\n"
     ]
    }
   ],
   "source": [
    "# Define file paths for the Book-Crossing datasets\n",
    "books_file_path = \"Books.csv\"  \n",
    "ratings_file_path = \"Ratings.csv\"\n",
    "users_file_path = \"Users.csv\"  \n",
    "\n",
    "# Load the datasets\n",
    "print(\"Loading Book-Crossing datasets...\")\n",
    "books = pd.read_csv(books_file_path, sep=';', encoding='latin-1', on_bad_lines='skip')\n",
    "ratings = pd.read_csv(ratings_file_path, sep=';', encoding='latin-1', on_bad_lines='skip')\n",
    "users = pd.read_csv(users_file_path, sep=';', encoding='latin-1', on_bad_lines='skip')\n",
    "\n",
    "# Preview of data basic data & columns\n",
    "print(books.head())\n",
    "print(books.columns)\n",
    "print(ratings.head())\n",
    "print(ratings.columns)\n",
    "print(users.head())\n",
    "print(users.columns)\n",
    "\n",
    "# Merge Ratings with Books\n",
    "print(\"Merging Ratings and Books datasets...\")\n",
    "merged_data = pd.merge(ratings, books, on=\"ISBN\", how=\"inner\")\n",
    "\n",
    "# Filter books with at least 50 ratings\n",
    "print(\"Filtering books with at least 50 ratings...\")\n",
    "# Count the number of ratings for each book (ISBN)\n",
    "book_counts = merged_data['ISBN'].value_counts()\n",
    "# Keep books that have been rated at least 50 times\n",
    "filtered_books = book_counts[book_counts >= 50].index\n",
    "filtered_data = merged_data[merged_data['ISBN'].isin(filtered_books)]\n",
    "\n",
    "# Filter users who have rated at least 50 books\n",
    "print(\"Filtering users who have rated at least 50 books...\")\n",
    "# Count the number of books rated by each user (User-ID)\n",
    "user_counts = filtered_data['User-ID'].value_counts()\n",
    "# Keep users who have rated at least 50 books\n",
    "filtered_users = user_counts[user_counts >= 50].index\n",
    "filtered_data = filtered_data[filtered_data['User-ID'].isin(filtered_users)]\n",
    "\n",
    "# Save the filtered dataset\n",
    "output_path = \"filtered_book_crossing.csv\"\n",
    "filtered_data.to_csv(output_path, index=False)\n",
    "print(f\"Filtered Book-Crossing dataset saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6567ec-7853-4f21-b511-19bce193a6f6",
   "metadata": {},
   "source": [
    "# Part 3: Verify and Inspect the Filtered Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c45ac47e-3d09-44d5-a7f2-cb8be0fb7079",
   "metadata": {},
   "source": [
    "#### - This part verifies the structure of the filtered dataset.\n",
    "#### - It ensures the filtering process was successful by displaying the dataset info and a few sample rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "051f2525-68e3-4344-a382-6dcecc03e62e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading filtered datasets...\n",
      "\n",
      "Filtered Book-Crossing Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95690 entries, 0 to 95689\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   User-ID    95690 non-null  int64 \n",
      " 1   ISBN       95690 non-null  object\n",
      " 2   Rating     95690 non-null  int64 \n",
      " 3   Title      95690 non-null  object\n",
      " 4   Author     95690 non-null  object\n",
      " 5   Year       95690 non-null  int64 \n",
      " 6   Publisher  95690 non-null  object\n",
      "dtypes: int64(3), object(4)\n",
      "memory usage: 5.1+ MB\n",
      "None\n",
      "Sample Rows:\n",
      "   User-ID        ISBN  Rating  \\\n",
      "0   277427  002542730X      10   \n",
      "1   277427  006092988X       0   \n",
      "2   277427  0060930535       0   \n",
      "3   277427  0060932139       0   \n",
      "4   277427  0060934417       0   \n",
      "\n",
      "                                               Title              Author  \\\n",
      "0  Politically Correct Bedtime Stories: Modern Ta...   James Finn Garner   \n",
      "1                           A Tree Grows in Brooklyn         Betty Smith   \n",
      "2                      The Poisonwood Bible: A Novel  Barbara Kingsolver   \n",
      "3  The Unbearable Lightness of Being : A Novel (P...       Milan Kundera   \n",
      "4                                 Bel Canto: A Novel        Ann Patchett   \n",
      "\n",
      "   Year              Publisher  \n",
      "0  1994  John Wiley & Sons Inc  \n",
      "1  1998              Perennial  \n",
      "2  1999              Perennial  \n",
      "3  1999              Perennial  \n",
      "4  2002              Perennial  \n"
     ]
    }
   ],
   "source": [
    "# File paths for the filtered datasets\n",
    "book_crossing_path = \"filtered_book_crossing.csv\"  # Replace with actual path\n",
    "\n",
    "# Load the filtered datasets\n",
    "print(\"Loading filtered datasets...\")\n",
    "filtered_book_crossing = pd.read_csv(book_crossing_path)\n",
    "\n",
    "# Display dataset info and sample rows\n",
    "print(\"\\nFiltered Book-Crossing Dataset Info:\")\n",
    "print(filtered_book_crossing.info())\n",
    "print(\"Sample Rows:\")\n",
    "print(filtered_book_crossing.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0558f74b-2d73-441d-af63-dc0ac9acd151",
   "metadata": {},
   "source": [
    "# Part 4: Download Dataset for Gender Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e72e38-2911-4661-a36f-84567bc044fe",
   "metadata": {},
   "source": [
    "#### - This part involves downloading the Gender-to-Name dataset.\n",
    "#### - This dataset will help map author names to genders for gender analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "f746803c-1710-4536-8380-5199223644a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\User\\.cache\\kagglehub\\datasets\\gracehephzibahm\\gender-by-name\\versions\\1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(      Name Gender    Count  Probability\n",
       " 0    James      M  5304407     0.014517\n",
       " 1     John      M  5260831     0.014398\n",
       " 2   Robert      M  4970386     0.013603\n",
       " 3  Michael      M  4579950     0.012534\n",
       " 4  William      M  4226608     0.011567,\n",
       " Index(['Name', 'Gender', 'Count', 'Probability'], dtype='object'))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"gracehephzibahm/gender-by-name\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)\n",
    "\n",
    "# Load the dataset to define gender_data\n",
    "Gender_to_Name_Path = \"data.csv\"  \n",
    "gender_data = pd.read_csv(Gender_to_Name_Path)\n",
    "\n",
    "# Verify the structure again\n",
    "gender_data.head(), gender_data.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e13306-a334-4291-a241-a2c1ed69402c",
   "metadata": {},
   "source": [
    "\n",
    "# Part 5: Gender Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d5c759-45b1-427c-90fd-b5c282cf118c",
   "metadata": {},
   "source": [
    "#### - This part performs gender analysis on the Book-Crossing dataset.\n",
    "#### - The goal is to map the authors' first names to genders using the Gender-to-Name dataset.\n",
    "#### - We also calculate and display the gender distribution of authors in the Book-Crossing dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "4b1d58a7-e080-4746-a3f8-1842af65cf50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Book-Crossing Dataset Gender Distribution:\n",
      "gender\n",
      "M          48077\n",
      "F          44802\n",
      "Unknown     2811\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Book-Crossing Dataset Gender Percentages:\n",
      "gender\n",
      "M          50.24\n",
      "F          46.82\n",
      "Unknown     2.94\n",
      "Name: count, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a gender dictionary from the gender_data dataset\n",
    "gender_dict = {name.lower(): gender for name, gender in zip(gender_data['Name'], gender_data['Gender'])}\n",
    "\n",
    "# Function to map genders to authors\n",
    "def map_gender(authors_list, gender_dict):\n",
    "    \"\"\"\n",
    "    Map the gender of authors based on the Gender-to-Name dataset.\n",
    "    \"\"\"\n",
    "    genders = []\n",
    "    for author in authors_list:\n",
    "        # Ensure the author is a valid string and handle NaN values\n",
    "        if isinstance(author, str):\n",
    "            # Get the first name from author (handling both single and multiple authors)\n",
    "            first_name = author.split()[0].strip(\"['\\\"]\").lower()\n",
    "            gender = gender_dict.get(first_name, 'Unknown')  # Default to 'Unknown' if name not found\n",
    "        else:\n",
    "            gender = 'Unknown'  # If the value is not a string, assign 'Unknown'\n",
    "        genders.append(gender)\n",
    "    return genders\n",
    "\n",
    "# Map genders to authors in the Book-Crossing dataset\n",
    "filtered_book_crossing['gender'] = map_gender(filtered_book_crossing['Author'], gender_dict)\n",
    "\n",
    "# Gender distribution analysis for Book-Crossing dataset\n",
    "book_crossing_gender_distribution = filtered_book_crossing['gender'].value_counts()\n",
    "book_crossing_total = book_crossing_gender_distribution.sum()\n",
    "book_crossing_gender_percentages = (book_crossing_gender_distribution / book_crossing_total * 100).round(2)\n",
    "\n",
    "print(\"\\nBook-Crossing Dataset Gender Distribution:\")\n",
    "print(book_crossing_gender_distribution)\n",
    "print(\"\\nBook-Crossing Dataset Gender Percentages:\")\n",
    "print(book_crossing_gender_percentages)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82c8cc6-d488-40fa-a8c1-c7a538c817a5",
   "metadata": {},
   "source": [
    "# Part 6: Debiasing the Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fce5304-9a6e-4c07-8672-9494bcf6d2cb",
   "metadata": {},
   "source": [
    "#### - This part adjusts the ratings to debias them based on gender.\n",
    "#### - Gender-based biases in user ratings are removed by normalizing ratings based on the gender average.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "cdb6aa25-30f9-47f0-a06c-873d7ea9e46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  Rating gender  \\\n",
      "0  Politically Correct Bedtime Stories: Modern Ta...      10      F   \n",
      "1                           A Tree Grows in Brooklyn       0      M   \n",
      "2                      The Poisonwood Bible: A Novel       0      M   \n",
      "3  The Unbearable Lightness of Being : A Novel (P...       0      F   \n",
      "4                                 Bel Canto: A Novel       0      M   \n",
      "\n",
      "   Rating_debias  \n",
      "0        8.06118  \n",
      "1       -1.98153  \n",
      "2       -1.98153  \n",
      "3       -1.93882  \n",
      "4       -1.98153  \n",
      "                                               Title  Rating gender  \\\n",
      "0  Politically Correct Bedtime Stories: Modern Ta...      10      F   \n",
      "1                           A Tree Grows in Brooklyn       0      M   \n",
      "2                      The Poisonwood Bible: A Novel       0      M   \n",
      "3  The Unbearable Lightness of Being : A Novel (P...       0      F   \n",
      "4                                 Bel Canto: A Novel       0      M   \n",
      "\n",
      "   Rating_debias  \n",
      "0        8.06118  \n",
      "1       -1.98153  \n",
      "2       -1.98153  \n",
      "3       -1.93882  \n",
      "4       -1.98153  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Debiasing function\n",
    "def debias_ratings(df, rating_col, gender_col):\n",
    "    \"\"\"\n",
    "    Adjust ratings to debias based on gender.\n",
    "    - Removes gender-based biases in user ratings.\n",
    "    \"\"\"\n",
    "    # Calculate average ratings for each gender\n",
    "    gender_avg_ratings = df.groupby(gender_col)[rating_col].mean()\n",
    "\n",
    "    # Normalize ratings for each user based on their gender\n",
    "    def adjust_rating(row):\n",
    "        if row[gender_col] == 'M':\n",
    "            return row[rating_col] - gender_avg_ratings['M']\n",
    "        elif row[gender_col] == 'F':\n",
    "            return row[rating_col] - gender_avg_ratings['F']\n",
    "        else:\n",
    "            return row[rating_col]  # For Unknown gender, leave the rating unchanged\n",
    "\n",
    "    df[rating_col + '_debias'] = df.apply(adjust_rating, axis=1)\n",
    "    return df\n",
    "\n",
    "# Apply debiasing to the Book-Crossing dataset\n",
    "book_crossing_debiased = debias_ratings(filtered_book_crossing, 'Rating', 'gender')\n",
    "\n",
    "# Display debiased data for Book-Crossing\n",
    "print(book_crossing_debiased[['Title', 'Rating', 'gender', 'Rating_debias']].head())\n",
    "\n",
    "# Step 4: For Book-Crossing, continue debiasing as usual\n",
    "book_crossing_debiased = debias_ratings(book_crossing_debiased, 'Rating', 'gender')\n",
    "\n",
    "# Step 5: Display debiased data for Book-Crossing\n",
    "print(book_crossing_debiased[['Title', 'Rating', 'gender', 'Rating_debias']].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87b6dcf0-5370-42dc-9ae6-0e53547a7197",
   "metadata": {},
   "source": [
    "# Log-Bias Adjustment for Ratings and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ba4618-2386-42ff-83ea-1e18464f0ac0",
   "metadata": {},
   "source": [
    "#### In this section, we first define a function to apply a log-bias transformation to the ratings data. \n",
    "#### The log transformation helps in reducing the impact of extreme ratings and normalizes the data.\n",
    "#### Then, we apply this log-bias adjustment to both the Amazon and Book-Crossing datasets.\n",
    "#### Finally, we visualize the distribution of the ratings before and after the debiasing process using histograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e33ede48-1e29-437f-a86f-022e71a9d259",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:399: RuntimeWarning: invalid value encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def log_bias_adjustment(df, rating_col):\n",
    "    df['log_bias'] = np.log(1 + df[rating_col])\n",
    "    return df\n",
    "\n",
    "# Apply log-bias transformation\n",
    "book_crossing_debiased = log_bias_adjustment(book_crossing_debiased, 'Rating_debias')\n",
    "\n",
    "# Visualize the distribution before and after debiasing\n",
    "plt.figure(figsize=(10,6))\n",
    "\n",
    "# Plot before debiasing (assuming original ratings are in 'Rating_debias' column)\n",
    "plt.hist(book_crossing_debiased['Rating_debias'], bins=50, alpha=0.5, label='Before Debiasing', color='b')\n",
    "\n",
    "# Plot after debiasing (log-transformed ratings)\n",
    "plt.hist(book_crossing_debiased['log_bias'], bins=50, alpha=0.5, label='After Debiasing', color='r')\n",
    "\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(\"Distribution of Ratings Before and After Debiasing\")\n",
    "plt.xlabel(\"Rating (Before) / Log-Bias (After)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976f4b78-a3b9-4cc2-9035-b4328b6adc85",
   "metadata": {},
   "source": [
    "# Installing and Importing Libraries for Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b678e9e7-8360-4d13-9358-6ebefce925ba",
   "metadata": {},
   "source": [
    "#### In this section, we install and import the scikit-surprise library, which provides a suite of tools for building collaborative filtering recommendation systems.\n",
    "#### We import models like SVD, NMF, and KNNBasic, as well as the necessary functions for dataset handling and performance evaluation (like RMSE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "d1c2a1c4-687b-44b7-b757-d7127206e6df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-surprise in c:\\users\\user\\anaconda3\\lib\\site-packages (1.1.4)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\user\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "# Install scikit-surprise\n",
    "!pip install scikit-surprise\n",
    "\n",
    "from surprise import SVD, NMF, KNNBasic\n",
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce7e2253-66e6-4e47-a75c-e67928f417c9",
   "metadata": {},
   "source": [
    "# Preparing the Dataset for Surprise Library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988b989d-6d5e-448b-892e-a3c01d53c8ca",
   "metadata": {},
   "source": [
    "#### Here, we prepare the data for the Surprise library by defining the rating scale (0-10) and converting the dataset into a format that Surprise understands.\n",
    "#### We split the dataset into training and testing sets, using an 80%-20% split to ensure that we can evaluate the model on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7878baba-2ea4-47ff-8604-fe597617857d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the dataset for Surprise\n",
    "reader = Reader(rating_scale=(0, 10))  # Ratings are from 0 to 10\n",
    "data = Dataset.load_from_df(filtered_book_crossing[['User-ID', 'ISBN', 'Rating']], reader)\n",
    "\n",
    "# Split data into training and testing sets (80%-20%)\n",
    "trainset, testset = train_test_split(data, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3421d4c5-e76e-46e1-8d66-7e574baa3c0d",
   "metadata": {},
   "source": [
    "# Training KNN Models for Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f7de64-b203-49b5-b09c-b247050bd1c6",
   "metadata": {},
   "source": [
    "#### This section involves training two types of K-Nearest Neighbors (KNN) models: User-based KNN and Item-based KNN.\n",
    "##### - User-based KNN recommends items based on similar users preferences.\n",
    "##### - Item-based KNN recommends items based on similarity between items.\n",
    "#### Both models are trained on the training set and then evaluated using the RMSE metric.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "72d9c1f3-d509-46cb-82ae-84f204857346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training UserKNN...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 3.5311\n",
      "\n",
      "Training ItemKNN...\n",
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "RMSE: 3.2992\n"
     ]
    }
   ],
   "source": [
    "# 1. KNN Algorithms\n",
    "# User-based collaborative filtering using KNN\n",
    "print(\"\\nTraining UserKNN...\")\n",
    "user_knn = KNNBasic(sim_options={'user_based': True})\n",
    "user_knn.fit(trainset)\n",
    "user_knn_preds = user_knn.test(testset)\n",
    "user_knn_rmse = accuracy.rmse(user_knn_preds)\n",
    "\n",
    "# Item-based collaborative filtering using KNN\n",
    "print(\"\\nTraining ItemKNN...\")\n",
    "item_knn = KNNBasic(sim_options={'user_based': False})\n",
    "item_knn.fit(trainset)\n",
    "item_knn_preds = item_knn.test(testset)\n",
    "item_knn_rmse = accuracy.rmse(item_knn_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55c5819-8156-479c-8952-ce1d020fe520",
   "metadata": {},
   "source": [
    "# Training Matrix Factorization Models (SVD and NMF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd576bb-c3f5-4fb7-9330-af52429016b8",
   "metadata": {},
   "source": [
    "#### In this section, we train two matrix factorization models: SVD (Singular Value Decomposition) and NMF (Non-negative Matrix Factorization).\n",
    "#### SVD is a popular method in collaborative filtering, using latent factors to model the user-item interaction.\n",
    "#### NMF is an alternative factorization technique that requires all data to be non-negative, making it useful in some recommendation tasks.\n",
    "#### Both models are trained on the training set, evaluated on the test set, and their performance is measured using RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "ee3bce49-ccb7-4f61-b6bb-bf972f995d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training SVD...\n",
      "RMSE: 3.3950\n",
      "\n",
      "Training NMF (for ALS alternative)...\n",
      "RMSE: 3.6825\n"
     ]
    }
   ],
   "source": [
    "# 2. Matrix Factorization Algorithms\n",
    "# Singular Value Decomposition (SVD)\n",
    "print(\"\\nTraining SVD...\")\n",
    "svd = SVD()\n",
    "svd.fit(trainset)\n",
    "svd_preds = svd.test(testset)\n",
    "svd_rmse = accuracy.rmse(svd_preds)\n",
    "\n",
    "# Alternating Least Squares (ALS) Using NMF as an Alternative\n",
    "print(\"\\nTraining NMF (for ALS alternative)...\")\n",
    "nmf = NMF()\n",
    "nmf.fit(trainset)\n",
    "nmf_preds = nmf.test(testset)\n",
    "nmf_rmse = accuracy.rmse(nmf_preds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3213102f-01e5-4419-81fe-ea5f56e2e2b2",
   "metadata": {},
   "source": [
    "# Evaluating the Models Using RMSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e31cc37-8efa-403a-8bc1-078547114dcf",
   "metadata": {},
   "source": [
    "#### The performance of each model is evaluated using the Root Mean Squared Error (RMSE), which provides a measure of how well the model's predictions match the actual ratings.\n",
    "#### A lower RMSE indicates a better performing model, so we compare the results from the KNN-based models and matrix factorization models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "a4fcec90-e3f1-44bd-9345-7def140dda35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RMSE Results:\n",
      "UserKNN RMSE: 3.531133247368096\n",
      "ItemKNN RMSE: 3.2991966375199535\n",
      "SVD RMSE: 3.395048218105989\n",
      "NMF RMSE: 3.6825304298247006\n"
     ]
    }
   ],
   "source": [
    "# Print RMSE values for evaluation\n",
    "print(\"\\nRMSE Results:\")\n",
    "print(f\"UserKNN RMSE: {user_knn_rmse}\")\n",
    "print(f\"ItemKNN RMSE: {item_knn_rmse}\")\n",
    "print(f\"SVD RMSE: {svd_rmse}\")\n",
    "print(f\"NMF RMSE: {nmf_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25e3055-714d-4a7f-8a63-d2b854db1b50",
   "metadata": {},
   "source": [
    "# Calculating Log-Bias for Users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964a4d2-2653-4e44-986b-e1be346e9e5c",
   "metadata": {},
   "source": [
    "#### The function calculate_log_bias calculates a log-bias for each user, where the log-bias is computed as the mean of the logarithm of non-zero ratings for each user.\n",
    "#### Grouping by User-ID: The ratings are grouped by User-ID so that we can calculate the log-bias for each user.\n",
    "#### Handling Zero Ratings: It skips zero ratings during the log-bias calculation to ensure they dont skew the result. If all ratings for a user are zero, a bias of 0 is assigned to that user.\n",
    "#### Log Calculation: It calculates the natural logarithm (np.log) of the non-zero ratings for each user, and the average of these values is returned as the user's log-bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "dfc20a4d-0278-4ac7-ab5a-cf85171d7864",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_log_bias(filtered_data):\n",
    "    \"\"\"\n",
    "    Calculate the log-bias (_u) for each user, skipping zero ratings.\n",
    "    \"\"\"\n",
    "    log_biases = {}\n",
    "    \n",
    "    # Group data by User-ID and calculate log-bias for each user\n",
    "    for user_id, group in filtered_data.groupby('User-ID'):\n",
    "        ratings = group['Rating'].values\n",
    "        \n",
    "        # Only include non-zero ratings in the log-bias calculation\n",
    "        non_zero_ratings = ratings[ratings > 0]\n",
    "        \n",
    "        # If the user has rated at least one non-zero item, calculate the log-bias\n",
    "        if len(non_zero_ratings) > 0:\n",
    "            log_bias = np.mean(np.log(non_zero_ratings))  # Calculate log of non-zero ratings\n",
    "        else:\n",
    "            log_bias = 0  # If all ratings are zero, set bias to 0 (or handle as you see fit)\n",
    "        \n",
    "        log_biases[user_id] = log_bias\n",
    "    \n",
    "    return log_biases\n",
    "\n",
    "# Calculate log-biases for each user, skipping zero ratings\n",
    "log_biases = calculate_log_bias(filtered_book_crossing)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f570d13-375d-4196-b8b4-68e268fc47e9",
   "metadata": {},
   "source": [
    "# Debiasing the Ratings Using Log-Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf3c80b-8a32-46d1-a327-c0631dbda4d3",
   "metadata": {},
   "source": [
    "#### The function calculate_debiased_ratings adjusts the ratings by subtracting each user's log-bias from their ratings. The goal is to eliminate biases in the ratings data that may have been introduced by individual users.\n",
    "#### Log-Bias Adjustment: The function loops through each row in the dataset and retrieves the corresponding users log-bias. If the log-bias for a user is not available, it defaults to 0.\n",
    "#### Debiased Rating: The debiased rating is calculated by subtracting the log-bias from the original rating, effectively removing any user-specific bias.\n",
    "#### Returning the Adjusted Data: The debiased ratings are added to the dataset as a new column (Debiased_Rating)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "3270ad8d-030f-44ef-8870-2171f6ed6519",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_debiased_ratings(filtered_data, log_biases):\n",
    "    \"\"\"\n",
    "    Adjust the ratings using the log-bias to create debiased ratings.\n",
    "    \"\"\"\n",
    "    debiased_ratings = []\n",
    "    \n",
    "    # Loop over each row to calculate the debiased rating\n",
    "    for _, row in filtered_data.iterrows():\n",
    "        user_id = row['User-ID']\n",
    "        rating = row['Rating']\n",
    "        \n",
    "        # Get the log-bias for the user\n",
    "        log_bias = log_biases.get(user_id, 0)  # Default to 0 if no log-bias exists\n",
    "        \n",
    "        # Calculate the debiased rating\n",
    "        debiased_rating = rating - log_bias\n",
    "        debiased_ratings.append(debiased_rating)\n",
    "    \n",
    "    # Add the debiased ratings as a new column\n",
    "    filtered_data['Debiased_Rating'] = debiased_ratings\n",
    "    return filtered_data\n",
    "\n",
    "# Apply debiasing to the filtered Book-Crossing dataset\n",
    "filtered_book_crossing = calculate_debiased_ratings(filtered_book_crossing, log_biases)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98be0e9f-bcbe-4df7-93e1-1a57b322e57f",
   "metadata": {},
   "source": [
    "# Reintroducing User-Specific Preferences: Preference Correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f29a4a-2980-4b4c-995f-f15a3468098a",
   "metadata": {},
   "source": [
    "#### The function apply_preference_correction reintroduces a user-specific preference to the debiased ratings.\n",
    "#### User-Specific Preference (alpha_u): A fixed value alpha_u is added to each debiased rating, allowing the model to adjust the ratings based on a user-specific parameter.\n",
    "#### Adjustment Process: The function loops over each row in the dataset, retrieves the debiased rating, and adds the value of alpha_u to it, which represents the user's preference.\n",
    "#### Returning the Adjusted Data: The adjusted ratings are stored in a new column (Adjusted_Rating), which is then returned as part of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "b3102c0d-fa42-4c0d-853d-00ffacdc8e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_preference_correction(filtered_data, alpha_u=0.5):\n",
    "    \"\"\"\n",
    "    Adjust the debiased ratings by reintroducing the user-specific preference.\n",
    "    \"\"\"\n",
    "    adjusted_ratings = []\n",
    "    \n",
    "    for _, row in filtered_data.iterrows():\n",
    "        debiased_rating = row['Debiased_Rating']\n",
    "        \n",
    "        # Apply user-specific preference parameter (alpha_u)\n",
    "        adjusted_rating = debiased_rating + alpha_u\n",
    "        adjusted_ratings.append(adjusted_rating)\n",
    "    \n",
    "    # Add the adjusted ratings as a new column\n",
    "    filtered_data['Adjusted_Rating'] = adjusted_ratings\n",
    "    return filtered_data\n",
    "\n",
    "# Example: Apply a fixed preference correction for each user\n",
    "alpha_u = 0.5  # Example value for user-specific preference (this can vary by user)\n",
    "filtered_book_crossing = apply_preference_correction(filtered_book_crossing, alpha_u)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf567c77-fa68-4f67-a82c-53630641ba58",
   "metadata": {},
   "source": [
    "# Training an SVD Model Using Debiased Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a71e0d7-88d4-4514-8611-96fb6a89f7cc",
   "metadata": {},
   "source": [
    "### Dataset Preparation:\n",
    "#### The Dataset and Reader from the Surprise library are used to prepare the dataset, which consists of user-item ratings that have been adjusted by reintroducing the user-specific preferences.\n",
    "#### We load the filtered_book_crossing data with the adjusted ratings (Adjusted_Rating) into the Dataset format suitable for collaborative filtering algorithms.\n",
    "### Data Splitting:\n",
    "#### The data is split into training and testing sets using train_test_split with an 80%-20% split, ensuring that the model is trained on 80% of the data and tested on the remaining 20%.\n",
    "### SVD Model Training:\n",
    "#### The SVD (Singular Value Decomposition) algorithm is used for matrix factorization. The model is trained on the training set (trainset_debiased) and evaluated on the test set (testset_debiased).\n",
    "### RMSE Evaluation:\n",
    "#### The Root Mean Squared Error (RMSE) is computed on the predictions made by the trained SVD model to evaluate its performance in terms of how well it predicts ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "de42fdc5-837f-416c-80a9-cbf8291810fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.3792\n",
      "SVD Debiased RMSE: 3.3791703091257865\n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, accuracy\n",
    "\n",
    "# Prepare the dataset for Surprise using the adjusted ratings\n",
    "reader = Reader(rating_scale=(0, 10))\n",
    "data_debiased = Dataset.load_from_df(filtered_book_crossing[['User-ID', 'ISBN', 'Adjusted_Rating']], reader)\n",
    "\n",
    "# Split data into training and testing sets (80%-20%)\n",
    "trainset_debiased, testset_debiased = train_test_split(data_debiased, test_size=0.2)\n",
    "\n",
    "# Train an SVD model using the debiased ratings\n",
    "svd_debiased = SVD()\n",
    "svd_debiased.fit(trainset_debiased)\n",
    "svd_debiased_preds = svd_debiased.test(testset_debiased)\n",
    "\n",
    "# Evaluate RMSE for the debiased model\n",
    "svd_debiased_rmse = accuracy.rmse(svd_debiased_preds)\n",
    "\n",
    "print(f\"SVD Debiased RMSE: {svd_debiased_rmse}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c72bc93-cbd4-4920-8a8b-1e64b293d794",
   "metadata": {},
   "source": [
    "# Evaluating SVD Model and Generating Top-N Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d702d65d-6825-4523-9d9b-9432ecbdc7b5",
   "metadata": {},
   "source": [
    "#### This section focuses on two main tasks:\n",
    "#### Training and evaluating an SVD model: The first part uses the Surprise library to evaluate a Singular Value Decomposition (SVD) model on the biased ratings.\n",
    "#### Generating Top-N Recommendations: The second part sorts the dataset based on the adjusted ratings (after debiasing) and generates top-N recommendations for each user.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "e16be551-ce48-4f24-977b-cb793ef13510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 3.4106\n",
      "SVD Biased RMSE: 3.4106161297882456\n",
      "[277427 278418    243    254    882   2276   2766   3363   4017   5903]\n",
      "       User-ID        ISBN                                              Title  \\\n",
      "63432   186570  0671789422                       Possessing the Secret of Joy   \n",
      "61737   180957  1400032717  The Curious Incident of the Dog in the Night-T...   \n",
      "73219   217318  0671042262                         The Blue Nowhere : A Novel   \n",
      "73186   217318  0446611611                                      City of Bones   \n",
      "73180   217318  0446607274    Angels Flight (Detective Harry Bosch Mysteries)   \n",
      "73152   217318  0312955006          The Concrete Blonde (A Harry Bosch Novel)   \n",
      "43049   126736  0553295772                                   Extreme Measures   \n",
      "58534   170861  0385504209                                  The Da Vinci Code   \n",
      "74731   223087  1400031346                 The No. 1 Ladies' Detective Agency   \n",
      "46869   135458  0553562738                                      Doomsday Book   \n",
      "46842   135458  0440217563                                            Voyager   \n",
      "46872   135458  0553573403  A Game of Thrones (A Song of Ice and Fire, Boo...   \n",
      "46844   135458  044022425X                                    Drums of Autumn   \n",
      "46838   135458  0440212561                                          Outlander   \n",
      "46841   135458  0440215625                                 Dragonfly in Amber   \n",
      "85719   245827  0451183665                                     A Case of Need   \n",
      "85659   245827  0399141146                          The Hundred Secret Senses   \n",
      "85696   245827  0440998050                                  A Wrinkle in Time   \n",
      "93944   270605  0446672211  Where the Heart Is (Oprah's Book Club (Paperba...   \n",
      "93949   270605  0452269571                            Bastard Out of Carolina   \n",
      "\n",
      "       Adjusted_Rating  \n",
      "63432         9.027127  \n",
      "61737         8.867333  \n",
      "73219         8.830741  \n",
      "73186         8.830741  \n",
      "73180         8.830741  \n",
      "73152         8.830741  \n",
      "43049         8.829592  \n",
      "58534         8.820171  \n",
      "74731         8.806216  \n",
      "46869         8.801938  \n",
      "46842         8.801938  \n",
      "46872         8.801938  \n",
      "46844         8.801938  \n",
      "46838         8.801938  \n",
      "46841         8.801938  \n",
      "85719         8.796138  \n",
      "85659         8.796138  \n",
      "85696         8.796138  \n",
      "93944         8.789161  \n",
      "93949         8.789161  \n"
     ]
    }
   ],
   "source": [
    "from surprise import Dataset, Reader\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import SVD, accuracy\n",
    "\n",
    "# Prepare the dataset for Surprise using the original ratings (biased)\n",
    "data_biased = Dataset.load_from_df(filtered_book_crossing[['User-ID', 'ISBN', 'Rating']], reader)\n",
    "\n",
    "# Split data into training and testing sets (80%-20%)\n",
    "trainset_biased, testset_biased = train_test_split(data_biased, test_size=0.2)\n",
    "\n",
    "# Train an SVD model using the biased ratings\n",
    "svd_biased = SVD()\n",
    "svd_biased.fit(trainset_biased)\n",
    "svd_biased_preds = svd_biased.test(testset_biased)\n",
    "\n",
    "# Evaluate RMSE for the biased model\n",
    "svd_biased_rmse = accuracy.rmse(svd_biased_preds)\n",
    "\n",
    "print(f\"SVD Biased RMSE: {svd_biased_rmse}\")\n",
    "\n",
    "# List all unique User-IDs in the filtered dataset\n",
    "available_users = filtered_book_crossing['User-ID'].unique()\n",
    "\n",
    "# Print the first 10 available User-IDs\n",
    "print(available_users[:10])\n",
    "\n",
    "# Step 1: Sort the filtered dataset based on Adjusted_Rating (debized ratings)\n",
    "filtered_book_crossing_sorted = filtered_book_crossing.sort_values(by='Adjusted_Rating', ascending=False)\n",
    "\n",
    "# Step 2: Display the top-N recommendations for each user\n",
    "# You can select the top 10 recommendations for each user, for example:\n",
    "top_n_recommendations = filtered_book_crossing_sorted.groupby('User-ID').head(10)\n",
    "\n",
    "# Display the top-N recommendations for the first few users\n",
    "print(top_n_recommendations[['User-ID', 'ISBN', 'Title', 'Adjusted_Rating']].head(20))  # Top 20 rows for example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769f0bb8-b11a-4629-8da3-e411058d7ede",
   "metadata": {},
   "source": [
    "# Calculating NDCG for Biased Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fdc183-baba-4833-8a98-8eab365ec599",
   "metadata": {},
   "source": [
    "#### The code below calculates the Normalized Discounted Cumulative Gain (NDCG) at k=10 for the recommendations based on the biased model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "7af9a25d-4313-416b-8762-ea4322c16f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG for Biased Model: 0.9663760896637609\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_ndcg_biased(predictions, k=10):\n",
    "    \"\"\"\n",
    "    Calculate the NDCG at k for the recommendations for the biased model.\n",
    "    \"\"\"\n",
    "    # Initialize lists for true relevance and predicted scores\n",
    "    y_true = []\n",
    "    y_score = []\n",
    "    \n",
    "    # Iterate over each user\n",
    "    for user_id in predictions['User-ID'].unique():\n",
    "        user_preds = predictions[predictions['User-ID'] == user_id].head(k)\n",
    "        \n",
    "        # Get the relevance (1 if Rating >= 8, else 0)\n",
    "        relevance = [1 if rating >= 8 else 0 for rating in user_preds['Rating']]\n",
    "        \n",
    "        # Get the predicted score (rating itself)\n",
    "        predicted_scores = user_preds['Rating'].values\n",
    "        \n",
    "        # Append the true relevance and predicted scores for this user\n",
    "        y_true.append(relevance)\n",
    "        y_score.append(predicted_scores)\n",
    "    \n",
    "    # Compute NDCG using sklearn's ndcg_score\n",
    "    return ndcg_score(y_true, y_score, k=k)\n",
    "\n",
    "# Calculate NDCG for the biased recommendations (using original ratings)\n",
    "ndcg_biased = calculate_ndcg_biased(filtered_book_crossing_sorted, k=10)\n",
    "print(f\"NDCG for Biased Model: {ndcg_biased}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6effb5-5403-4723-9351-5a950ec45c16",
   "metadata": {},
   "source": [
    "# Calculating NDCG for the Debiased Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7efa025-2df2-4ca7-bcd5-91707588c779",
   "metadata": {},
   "source": [
    "#### This part of the code calculates the Normalized Discounted Cumulative Gain (NDCG) at k for the recommendations generated using the debiased ratings. NDCG is a metric used to measure the effectiveness of recommendation systems by considering how well the system ranks relevant items (based on the adjusted ratings).\n",
    "#### - True Relevance: For each user, if the Adjusted_Rating is greater than or equal to 8, the item is considered relevant (with a relevance of 1). Otherwise, it is considered irrelevant (with a relevance of 0).\n",
    "#### - Predicted Scores: The predicted scores for ranking are the Adjusted_Rating values for each item.\n",
    "#### The function iterates over each user in the dataset, computes the relevance and predicted score for the top-k items, and then calculates the NDCG score using sklearn's ndcg_score function. The NDCG score gives an indication of how well the system ranks the most relevant items for each user.\n",
    "#### The final NDCG score is printed for the Debiased Model, which reflects how effectively the system performs in ranking items with higher relevance according to the debiased ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "aa2f7b52-5aca-448a-8d79-42c3b23edf1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG for Debiased Model: 0.800747198007472\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import ndcg_score\n",
    "import numpy as np\n",
    "\n",
    "def calculate_ndcg_debiased(predictions, k=10):\n",
    "    \"\"\"\n",
    "    Calculate the NDCG at k for the recommendations for the debiased model.\n",
    "    \"\"\"\n",
    "    y_true = []  # True relevance (1 for relevant, 0 for not relevant)\n",
    "    y_score = []  # Predicted relevance score (Adjusted_Rating)\n",
    "\n",
    "    # Iterate over each user in the dataset\n",
    "    for user_id in predictions['User-ID'].unique():\n",
    "        user_preds = predictions[predictions['User-ID'] == user_id].head(k)\n",
    "        \n",
    "        # Get the relevance (1 if Adjusted_Rating >= 8, else 0)\n",
    "        relevance = [1 if rating >= 8 else 0 for rating in user_preds['Adjusted_Rating']]\n",
    "        \n",
    "        # Get the predicted score (Adjusted_Rating itself)\n",
    "        predicted_scores = user_preds['Adjusted_Rating'].values\n",
    "        \n",
    "        # Append the true relevance and predicted scores for this user\n",
    "        y_true.append(relevance)\n",
    "        y_score.append(predicted_scores)\n",
    "    \n",
    "    # Compute NDCG using sklearn's ndcg_score function\n",
    "    return ndcg_score(y_true, y_score, k=k)\n",
    "\n",
    "# Calculate NDCG for the debiased recommendations (using Adjusted_Rating)\n",
    "ndcg_debiased = calculate_ndcg_debiased(filtered_book_crossing_sorted, k=10)\n",
    "\n",
    "# Print the NDCG score for the debiased model\n",
    "print(f\"NDCG for Debiased Model: {ndcg_debiased}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819a7595-7847-414e-a017-a521d655520d",
   "metadata": {},
   "source": [
    "# Calculating Mean Reciprocal Rank (MRR) for the Biased Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6522d6e-aad8-468e-b112-73c574b7dad4",
   "metadata": {},
   "source": [
    "#### This part of the code calculates the Mean Reciprocal Rank (MRR) for the recommendations generated using the biased ratings (original ratings). MRR is a metric used to evaluate recommendation systems based on how quickly relevant items appear in the ranked list of recommendations.\n",
    "\n",
    "#### -  Reciprocal Rank: For each user, the reciprocal rank is computed as the inverse of the position of the first relevant item. If the first relevant item appears at rank r, the reciprocal rank is 1/r.\n",
    "#### - Relevance Criteria: An item is considered relevant if its Rating is greater than or equal to 8.\n",
    "#### The function iterates over each user, finds the first relevant item, computes its reciprocal rank, and accumulates the result. If no relevant item is found, the reciprocal rank is considered as 0 for that user.\n",
    "\n",
    "#### Finally, the Mean Reciprocal Rank (MRR) is calculated by averaging the reciprocal ranks across all users in the dataset. This gives an indication of how well the system ranks relevant items for users on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "180468b0-9015-4700-9db2-ff9a5d8198b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR for Biased Model: 0.9663760896637609\n"
     ]
    }
   ],
   "source": [
    "def calculate_mrr_biased(predictions, k=10):\n",
    "    \"\"\"\n",
    "    Calculate Mean Reciprocal Rank (MRR) for the top-k recommendations for the biased model.\n",
    "    \"\"\"\n",
    "    mrr = 0.0\n",
    "    num_users = predictions['User-ID'].nunique()\n",
    "\n",
    "    # Iterate over each user in the dataset\n",
    "    for user_id in predictions['User-ID'].unique():\n",
    "        user_preds = predictions[predictions['User-ID'] == user_id].head(k)\n",
    "        \n",
    "        # Find the first relevant item (Rating >= 8)\n",
    "        relevant_items = user_preds[user_preds['Rating'] >= 8]\n",
    "        \n",
    "        if len(relevant_items) > 0:\n",
    "            # Reciprocal rank of the first relevant item\n",
    "            rank = 1 / (user_preds.index.get_loc(relevant_items.index[0]) + 1)\n",
    "            mrr += rank\n",
    "        else:\n",
    "            mrr += 0  # No relevant item found\n",
    "    \n",
    "    # Calculate MRR as the mean across all users\n",
    "    return mrr / num_users\n",
    "\n",
    "# Calculate MRR for the biased recommendations (using original ratings)\n",
    "mrr_biased = calculate_mrr_biased(filtered_book_crossing_sorted, k=10)\n",
    "print(f\"MRR for Biased Model: {mrr_biased}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e068994e-9c52-49a5-999d-6da6898c22c4",
   "metadata": {},
   "source": [
    "# Calculating Mean Reciprocal Rank (MRR) for the Debiased Model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2984d53-1673-4821-96a0-be7ddb8e01c0",
   "metadata": {},
   "source": [
    "#### This section of the code calculates the Mean Reciprocal Rank (MRR) for the top-k recommendations for the debiased model. MRR is an evaluation metric used to assess recommendation systems, based on the rank at which a relevant item is found in the recommendation list.\n",
    "\n",
    "#### Reciprocal Rank: The reciprocal rank is the inverse of the position of the first relevant item in the recommendation list. For example, if the first relevant item is ranked 1st, the reciprocal rank is 1. If it is ranked 2nd, the reciprocal rank is 1/2, and so on.\n",
    "#### Relevance Criteria: In this case, an item is considered relevant if its Adjusted_Rating is greater than or equal to 8.\n",
    "#### The function goes through each users recommendations, finds the first relevant item based on the adjusted ratings, calculates its reciprocal rank, and accumulates this value for all users. If no relevant item is found, the reciprocal rank for that user is considered 0.\n",
    "\n",
    "#### Finally, the Mean Reciprocal Rank (MRR) is calculated as the average of the reciprocal ranks across all users. A higher MRR indicates that relevant items tend to appear higher in the recommendation list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "ee3dd25f-155f-4e6e-a7e4-d40e9f5ee4bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MRR for Debiased Model: 0.800747198007472\n"
     ]
    }
   ],
   "source": [
    "def calculate_mrr_debiased(predictions, k=10):\n",
    "    \"\"\"\n",
    "    Calculate Mean Reciprocal Rank (MRR) for the top-k recommendations for the debiased model.\n",
    "    \"\"\"\n",
    "    mrr = 0.0\n",
    "    num_users = predictions['User-ID'].nunique()\n",
    "\n",
    "    # Iterate over each user in the dataset\n",
    "    for user_id in predictions['User-ID'].unique():\n",
    "        user_preds = predictions[predictions['User-ID'] == user_id].head(k)\n",
    "        \n",
    "        # Find the first relevant item (Adjusted_Rating >= 8)\n",
    "        relevant_items = user_preds[user_preds['Adjusted_Rating'] >= 8]\n",
    "        \n",
    "        if len(relevant_items) > 0:\n",
    "            # Reciprocal rank of the first relevant item\n",
    "            rank = 1 / (user_preds.index.get_loc(relevant_items.index[0]) + 1)\n",
    "            mrr += rank\n",
    "        else:\n",
    "            mrr += 0  # No relevant item found\n",
    "    \n",
    "    # Calculate MRR as the mean across all users\n",
    "    return mrr / num_users\n",
    "\n",
    "# Calculate MRR for the debiased recommendations (using Adjusted_Rating)\n",
    "mrr_debiased = calculate_mrr_debiased(filtered_book_crossing_sorted, k=10)\n",
    "print(f\"MRR for Debiased Model: {mrr_debiased}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
